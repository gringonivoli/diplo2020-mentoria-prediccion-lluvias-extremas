{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TP3: Introducción al aprendizaje automático"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "Datos = pd.read_csv(\"https://raw.githubusercontent.com/Rondamon/2020_Mentoria_LluviasExtremas/master/dataset/datos_diarios_cordoba.csv\", parse_dates = True, index_col=\"fecha\")\n",
    "id_Datos = pd.read_csv(\"https://raw.githubusercontent.com/Rondamon/2020_Mentoria_LluviasExtremas/master/dataset/metadatos_estaciones.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De los datasets analizados en los TPs anteriores, ahora nos vamos a enfocar en:\n",
    "\n",
    "- La Florida\n",
    "- Marcos Juarez\n",
    "\n",
    "Y vamos a usar como variable que queremos predecir, la PMDA que han calculado para cada año hidrológico (del 1/julio al 30/junio).\n",
    "\n",
    "Las demás variables (como viento, temperatura, etc) las vamos a resumir para cada año hidrológico en la media (se pueden agregar más estadísticos pero así es suficiente)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Actividades:\n",
    "\n",
    "##### OBJETIVO: Predecir Precipitación Máxima Diaria Anual (PMDA) para los próximos 5 años"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) De los dataset que han trabajado hasta ahora, agreguen más features al DataFrame **\"Datos\"** (Por lo general, más features tienden a dar mejores predicciones).\n",
    "\n",
    "2) Además de las features del punto anterior, les propongo agregar nuevas features moviendo las originales tantos \"pasos de tiempo\" como features nuevas quieran generar.\n",
    "\n",
    "3) Curar el dataset (si fuera necesario).\n",
    "\n",
    "4) Aplicar técnicas de selección y extraccion de features. Armar un nuevo dataset con aquellas features más significativas.\n",
    "\n",
    "5) Dividir el dataset (training, validation, test).. Recuerden que queremos predecir la PMDA para los próximos 5 años.\n",
    "\n",
    "6) Analizar y elegir 3 modelos para REGRESIÓN. Entrenarlos y analizar resultados.\n",
    "\n",
    "7) Evaluar predicciones de los diferentes modelos.\n",
    "\n",
    "8) ¿Qué estadísticos utilizaron para evaluar las regresiones? Justifiquen su elección."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = pd.read_csv('./datasetTP2/datos_diarios_cordoba_terra_chirps.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/pandas/core/indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "dataset = full_dataset[(full_dataset['nombre'] == 'La Florida') | (full_dataset['nombre'] == 'Marcos Juarez INTA')]\n",
    "dataset.loc[:, 'fecha'] = pd.to_datetime(dataset['fecha'])\n",
    "dataset.reset_index(inplace=True)\n",
    "dataset = dataset.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hydro_year(date_, start_month=7):\n",
    "    year = date_.strftime('%Y')\n",
    "    month = date_.strftime('%m')\n",
    "    offset = 1 if int(month) >= start_month - 1 else 0\n",
    "    hydro_year = int(year) + offset - 1\n",
    "    return hydro_year\n",
    "\n",
    "def add_hydro_year(dataset):\n",
    "    dataset = dataset.copy()\n",
    "    dataset.reset_index(inplace=True)\n",
    "    dataset['hydro_year'] = dataset['fecha'].apply(get_hydro_year)\n",
    "    return dataset\n",
    "\n",
    "def remove_cols(dataset, cols=['level_0', 'ano', 'mes', 'caudal', 'tmed', 'vmax_d', 'vmax_f']):\n",
    "    return dataset.drop(cols, axis=1)\n",
    "\n",
    "def get_grouped_dataset(dataset, group=['omm_id', 'hydro_year']):\n",
    "    return dataset.groupby(group)\n",
    "\n",
    "def derive_nth_day_feature(df, feature, N):\n",
    "    rows = df.shape[0]\n",
    "    nth_prior_measurements = [None]*N + [df[feature][i-N] for i in range(N, rows)]\n",
    "    col_name = \"{}_{}\".format(feature, N)\n",
    "    df[col_name] = nth_prior_measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = add_hydro_year(dataset)\n",
    "dataset = remove_cols(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>fecha</th>\n",
       "      <th>omm_id</th>\n",
       "      <th>nombre</th>\n",
       "      <th>prcp</th>\n",
       "      <th>tmax</th>\n",
       "      <th>tmin</th>\n",
       "      <th>vmed</th>\n",
       "      <th>ETreal_mm</th>\n",
       "      <th>HumedadSuelo_mm</th>\n",
       "      <th>RadSolar_Wpm2</th>\n",
       "      <th>PresionVapor_hPa</th>\n",
       "      <th>IndicePalmer_porc</th>\n",
       "      <th>hydro_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41353</th>\n",
       "      <td>84826</td>\n",
       "      <td>2018-11-24</td>\n",
       "      <td>1</td>\n",
       "      <td>La Florida</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.4</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5.38</td>\n",
       "      <td>114.5</td>\n",
       "      <td>68.0</td>\n",
       "      <td>258.1</td>\n",
       "      <td>12.26</td>\n",
       "      <td>1.29</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41354</th>\n",
       "      <td>84827</td>\n",
       "      <td>2018-11-25</td>\n",
       "      <td>1</td>\n",
       "      <td>La Florida</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.4</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5.38</td>\n",
       "      <td>114.5</td>\n",
       "      <td>68.0</td>\n",
       "      <td>258.1</td>\n",
       "      <td>12.26</td>\n",
       "      <td>1.29</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41355</th>\n",
       "      <td>84828</td>\n",
       "      <td>2018-11-26</td>\n",
       "      <td>1</td>\n",
       "      <td>La Florida</td>\n",
       "      <td>21.5</td>\n",
       "      <td>24.4</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5.38</td>\n",
       "      <td>114.5</td>\n",
       "      <td>68.0</td>\n",
       "      <td>258.1</td>\n",
       "      <td>12.26</td>\n",
       "      <td>1.29</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41356</th>\n",
       "      <td>84829</td>\n",
       "      <td>2018-11-27</td>\n",
       "      <td>1</td>\n",
       "      <td>La Florida</td>\n",
       "      <td>94.0</td>\n",
       "      <td>24.4</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5.38</td>\n",
       "      <td>114.5</td>\n",
       "      <td>68.0</td>\n",
       "      <td>258.1</td>\n",
       "      <td>12.26</td>\n",
       "      <td>1.29</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41357</th>\n",
       "      <td>84830</td>\n",
       "      <td>2018-11-28</td>\n",
       "      <td>1</td>\n",
       "      <td>La Florida</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.4</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5.38</td>\n",
       "      <td>114.5</td>\n",
       "      <td>68.0</td>\n",
       "      <td>258.1</td>\n",
       "      <td>12.26</td>\n",
       "      <td>1.29</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index      fecha  omm_id      nombre  prcp  tmax  tmin  vmed  \\\n",
       "41353  84826 2018-11-24       1  La Florida   0.0  24.4  10.5  5.38   \n",
       "41354  84827 2018-11-25       1  La Florida   0.0  24.4  10.5  5.38   \n",
       "41355  84828 2018-11-26       1  La Florida  21.5  24.4  10.5  5.38   \n",
       "41356  84829 2018-11-27       1  La Florida  94.0  24.4  10.5  5.38   \n",
       "41357  84830 2018-11-28       1  La Florida   0.0  24.4  10.5  5.38   \n",
       "\n",
       "       ETreal_mm  HumedadSuelo_mm  RadSolar_Wpm2  PresionVapor_hPa  \\\n",
       "41353      114.5             68.0          258.1             12.26   \n",
       "41354      114.5             68.0          258.1             12.26   \n",
       "41355      114.5             68.0          258.1             12.26   \n",
       "41356      114.5             68.0          258.1             12.26   \n",
       "41357      114.5             68.0          258.1             12.26   \n",
       "\n",
       "       IndicePalmer_porc  hydro_year  \n",
       "41353               1.29        2018  \n",
       "41354               1.29        2018  \n",
       "41355               1.29        2018  \n",
       "41356               1.29        2018  \n",
       "41357               1.29        2018  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'fecha', 'omm_id', 'nombre', 'prcp', 'tmax', 'tmin', 'vmed',\n",
       "       'ETreal_mm', 'HumedadSuelo_mm', 'RadSolar_Wpm2', 'PresionVapor_hPa',\n",
       "       'IndicePalmer_porc', 'hydro_year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_columns = ['tmax', 'tmin', 'vmed',\n",
    "       'ETreal_mm', 'HumedadSuelo_mm', 'RadSolar_Wpm2', 'PresionVapor_hPa',\n",
    "       'IndicePalmer_porc']\n",
    "target = ['prcp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in features_columns:\n",
    "    if feature != 'prcp':\n",
    "        for N in range(1, 4):\n",
    "            derive_nth_day_feature(dataset, feature, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(dataset.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'fecha', 'omm_id', 'nombre', 'prcp', 'tmax', 'tmin', 'vmed',\n",
       "       'ETreal_mm', 'HumedadSuelo_mm', 'RadSolar_Wpm2', 'PresionVapor_hPa',\n",
       "       'IndicePalmer_porc', 'hydro_year', 'tmax_1', 'tmax_2', 'tmax_3',\n",
       "       'tmin_1', 'tmin_2', 'tmin_3', 'vmed_1', 'vmed_2', 'vmed_3',\n",
       "       'ETreal_mm_1', 'ETreal_mm_2', 'ETreal_mm_3', 'HumedadSuelo_mm_1',\n",
       "       'HumedadSuelo_mm_2', 'HumedadSuelo_mm_3', 'RadSolar_Wpm2_1',\n",
       "       'RadSolar_Wpm2_2', 'RadSolar_Wpm2_3', 'PresionVapor_hPa_1',\n",
       "       'PresionVapor_hPa_2', 'PresionVapor_hPa_3', 'IndicePalmer_porc_1',\n",
       "       'IndicePalmer_porc_2', 'IndicePalmer_porc_3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_features_cols = ['index', 'fecha', 'omm_id', 'nombre', 'prcp']\n",
    "features_columns = [col for col in dataset.columns if col not in not_features_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((39267, 33), (39267, 1))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_dataset = dataset[features_columns]\n",
    "target_df = dataset[target]\n",
    "features_dataset.shape, target_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((31413, 33), (7854, 33))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = features_dataset.copy()\n",
    "y = target_df.copy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(30,20))\n",
    "# fig.subplots_adjust(hspace=0.5, wspace=0.5)\n",
    "\n",
    "# i = 1\n",
    "# for feature in features_columns:\n",
    "#     ax = fig.add_subplot(3, 5, i)\n",
    "#     plt.scatter(X.loc[:, feature], y, facecolor='dodgerblue', edgecolor='k', label='datos')\n",
    "#     plt.title(feature)\n",
    "#     i += 1\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((31413, 33), (7854, 33))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature = ['vmed', 'vmed_2']\n",
    "# X_train_f = X_train.loc[:, feature]\n",
    "# X_test_f = X_test.loc[:, feature]\n",
    "X_train_f = X_train\n",
    "X_test_f = X_test\n",
    "X_train_f.shape, X_test_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = LinearRegression()\n",
    "# model.fit(X_train_f, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train_pred = model.predict(X_train_f)\n",
    "# y_test_pred = model.predict(X_test_f)\n",
    "\n",
    "# train_error = mean_squared_error(y_train, y_train_pred)\n",
    "# test_error = mean_squared_error(y_test, y_test_pred)\n",
    "# print(f'Train error: {train_error}')\n",
    "# print(f'Test error: {test_error}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train:\n",
    "model = make_pipeline(PolynomialFeatures(3), LinearRegression())\n",
    "model.fit(X_train_f, y_train)\n",
    "\n",
    "# predict:\n",
    "y_train_pred = model.predict(X_train_f)\n",
    "y_test_pred = model.predict(X_test_f)\n",
    "\n",
    "# evaluate:\n",
    "train_error = mean_squared_error(y_train, y_train_pred)\n",
    "test_error = mean_squared_error(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_error, test_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
